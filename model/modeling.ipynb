{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "roman-green",
   "metadata": {},
   "source": [
    "# Preprocesing\n",
    "\n",
    "## Obtaining Data\n",
    "\n",
    "The following block is not going to be in the final pipeline, it is just a short version of the ETL, for quick experimentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "packed-negative",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-6-5276b5d0509b>:36: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  df_general = df.copy().drop(dropped_columns + to_other_tables, 1)\n"
     ]
    }
   ],
   "source": [
    "### DATA PREPROCESING\n",
    "\n",
    "import pandas as pd\n",
    "import yaml\n",
    "import numpy as np\n",
    "\n",
    "### User defined\n",
    "import variables_n_functions as vnf\n",
    "\n",
    "config_file = open('config.yaml', 'r')\n",
    "config = yaml.safe_load(config_file)\n",
    "\n",
    "teams = config['teams']\n",
    "\n",
    "\n",
    "### We initialize the df with the appropriate column names\n",
    "df = pd.DataFrame(columns = vnf.columnas_df)\n",
    "\n",
    "### The following variable is auxiliar to avoid duplicate requests\n",
    "teams_aux = list(teams.keys())\n",
    "\n",
    "### We recover the match history between every unique team - team combination, and store it in the df\n",
    "for team_1 in teams.keys():\n",
    "    teams_aux.remove(team_1)\n",
    "    for team_2 in teams_aux:\n",
    "        h2h = vnf.head2head(team_1, team_2, config['sports_token'])\n",
    "        df = pd.concat([df] + [pd.DataFrame(pd.Series(h2h[k])).transpose() for k in range(len(h2h))])        \n",
    "\n",
    "### Define columns to drop or that will be added to other tables\n",
    "dropped_columns = ['details']\n",
    "to_other_tables = ['weather_report', 'formations', 'scores', 'time', 'coaches', 'standings', 'assistants', 'colors']\n",
    "\n",
    "config_file = open('config.yaml', 'r')\n",
    "config = yaml.safe_load(config_file)\n",
    "\n",
    "df_general = df.copy().drop(dropped_columns + to_other_tables, 1)\n",
    "\n",
    "df_scores = pd.DataFrame(columns = ['id', 'localteam_score', 'visitorteam_score', 'localteam_pen_score',\n",
    "                                    'visitorteam_pen_score', 'ht_score', 'ft_score', 'et_score', 'ps_score'])\n",
    "for k in range(df.shape[0]):\n",
    "#     temp = pd.DataFrame({key:[value] for key,value in eval(df['scores'].iloc[k]).items()})\n",
    "    temp = pd.DataFrame({key:[value] for key,value in df['scores'].iloc[k].items()})\n",
    "    temp['id'] = df.iloc[k]['id']\n",
    "    df_scores = pd.concat([df_scores, temp])\n",
    "    \n",
    "#################### Transformations ####################\n",
    "    \n",
    "###### h2h.general\n",
    "\n",
    "### ID variables\n",
    "df_general['id'] = df_general['id']\n",
    "df_general['league_id'] = df_general['league_id'].fillna(-1)\n",
    "df_general['season_id'] = df_general['season_id'].fillna(-1)\n",
    "df_general['stage_id'] = df_general['stage_id'].fillna(-1)\n",
    "df_general['round_id'] = df_general['round_id'].fillna(-1)\n",
    "df_general['group_id'] = df_general['group_id'].fillna(-1)\n",
    "df_general['aggregate_id'] = df_general['aggregate_id'].fillna(-1)\n",
    "df_general['venue_id'] = df_general['venue_id'].fillna(-1)\n",
    "df_general['referee_id'] = df_general['referee_id'].fillna(-1)\n",
    "df_general['localteam_id'] = df_general['localteam_id'].fillna(-1)\n",
    "df_general['visitorteam_id'] = df_general['visitorteam_id'].fillna(-1)\n",
    "df_general['winner_team_id'] = df_general['winner_team_id'].fillna(-1)\n",
    "\n",
    "### Other variables\n",
    "df_general['commentaries'] = df_general['commentaries'].apply(vnf.booleanize)# Boolean\n",
    "df_general['attendance'] = df_general['attendance'].fillna(-1)# Integer\n",
    "df_general['pitch'] = df_general['pitch'].apply(lambda x: \"None\" if x is None else x) # Categorical\n",
    "df_general['neutral_venue'] = df_general['neutral_venue'].apply(vnf.booleanize)# Boolean\n",
    "df_general['winning_odds_calculated'] = df_general['winning_odds_calculated'].apply(vnf.booleanize)# Boolean\n",
    "df_general['deleted'] = df_general['deleted'].apply(vnf.booleanize)# Boolean\n",
    "df_general['is_placeholder'] = df_general['is_placeholder'].apply(vnf.booleanize)# Boolean\n",
    "df_general['leg'] = df_general['leg'].fillna(-1)\n",
    "\n",
    "###### h2h.scores\n",
    "\n",
    "df_scores['id'] = df_scores['id']\n",
    "df_scores['localteam_score'] = df_scores['localteam_score'].fillna(-1)# Integer\n",
    "df_scores['visitorteam_score'] = df_scores['visitorteam_score'].fillna(-1)# Integer\n",
    "df_scores['localteam_pen_score'] = df_scores['localteam_pen_score'].fillna(-1)# Integer\n",
    "df_scores['visitorteam_pen_score'] = df_scores['visitorteam_pen_score'].fillna(-1)# Integer\n",
    "df_scores['ht_score'] = df_scores['ht_score'].fillna(-1) # String\n",
    "df_scores['ft_score'] = df_scores['ft_score'].fillna(-1) # String\n",
    "df_scores['et_score'] = df_scores['et_score'].fillna(-1) # String\n",
    "df_scores['ps_score'] = df_scores['ps_score'].fillna(-1) # String\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accredited-visitor",
   "metadata": {},
   "source": [
    "## Defining the Y\n",
    "\n",
    "The next chunk still is preprocesing, however in this section, we are going to adequate out dataframe to be ready to be used by different models, in a very simple way. Thus we will:\n",
    "\n",
    "+ select only a few variables that we will use in this first iteration\n",
    "+ give proper format to the dataframe\n",
    "+ propose different Ys for different experiments\n",
    "\n",
    "We have two kinds of models: overal match predictors and only winning predictor. In the former ones we are estimating the amount of goals for each team, this is normally done parametrically in more classical models, however, for the sake of the experiment, we tried naive regressions to estimate goals. This model is useful because it can predict winners, loosers, tie events, amount of goals, and different scenarios, the bad thing is that our design is pretty naive (the desgining of the proper model can be a whole thesis). In the latter models, less ambitious more powerful, we are only predicting if the home team is going to win or if it will loose or tie. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "several-female",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Y definition\n",
    "\n",
    "# Add index to dataframe\n",
    "new_index = [i for i in range(len(df_general))]\n",
    "df_general.index = new_index\n",
    "\n",
    "# Create Y variable: 1 if local wins, 0 in any other case\n",
    "df_general['Y'] = np.where(df_general['winner_team_id']==df_general['localteam_id'], 1, 0)\n",
    "\n",
    "# Filter only simpler columns\n",
    "dat=df_general[[\"league_id\",\"season_id\",\"venue_id\",\"referee_id\",\"localteam_id\",'visitorteam_id']]\n",
    "\n",
    "#dat1=pd.json_normalize(df[\"formations\"])\n",
    "#dat2=pd.json_normalize(df[\"scores\"])\n",
    "#dat3=pd.json_normalize(df[\"time\"])\n",
    "#dat4=pd.json_normalize(df[\"coaches\"])\n",
    "dat5=pd.json_normalize(df[\"standings\"])\n",
    "#dat6=pd.json_normalize(df[\"assistants\"])\n",
    "data=pd.concat([dat,dat5], axis=1)\n",
    "X = pd.get_dummies(data)\n",
    "\n",
    "# This is a naive treatment to dataframe\n",
    "X=X.fillna(0) \n",
    "X = X.replace([np.inf, -np.inf], np.nan)\n",
    "X = X.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "hispanic-regulation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ys definition\n",
    "\n",
    "# Canonical Y variable: 1 if local wins, 0 in any other case\n",
    "y = df_general['Y']\n",
    "\n",
    "# 2 alternative Ys, amount of goals for local and visitor\n",
    "\n",
    "df_scores.index = new_index\n",
    "y_goals_local = df_scores['localteam_score']\n",
    "y_goals_visitor = df_scores['visitorteam_score']\n",
    "\n",
    "# Finally, win, loose or tie labels.\n",
    "y_multi = np.where(df_general['winner_team_id']==-1, \"Empate\", \n",
    "                  np.where(df_general['winner_team_id']==df_general['localteam_id'], \"Local\", \"Visitante\"))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-pharmaceutical",
   "metadata": {},
   "source": [
    "As you can see, our X is pretty simple and pretty small. We learned that a lot of the variables were really noisy and had a negative impact in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "expressed-payroll",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>league_id</th>\n",
       "      <th>season_id</th>\n",
       "      <th>venue_id</th>\n",
       "      <th>referee_id</th>\n",
       "      <th>localteam_id</th>\n",
       "      <th>visitorteam_id</th>\n",
       "      <th>localteam_position</th>\n",
       "      <th>visitorteam_position</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>501</td>\n",
       "      <td>18369</td>\n",
       "      <td>8914</td>\n",
       "      <td>14859</td>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>501</td>\n",
       "      <td>18369</td>\n",
       "      <td>8909</td>\n",
       "      <td>14853</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>501</td>\n",
       "      <td>18369</td>\n",
       "      <td>8914</td>\n",
       "      <td>18748</td>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>6.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>501</td>\n",
       "      <td>17141</td>\n",
       "      <td>8914</td>\n",
       "      <td>14468</td>\n",
       "      <td>62</td>\n",
       "      <td>53</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>501</td>\n",
       "      <td>17141</td>\n",
       "      <td>8909</td>\n",
       "      <td>14859</td>\n",
       "      <td>53</td>\n",
       "      <td>62</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2086</th>\n",
       "      <td>2086</td>\n",
       "      <td>501</td>\n",
       "      <td>1932</td>\n",
       "      <td>219</td>\n",
       "      <td>17252</td>\n",
       "      <td>734</td>\n",
       "      <td>496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2087</th>\n",
       "      <td>2087</td>\n",
       "      <td>501</td>\n",
       "      <td>1931</td>\n",
       "      <td>219</td>\n",
       "      <td>70310</td>\n",
       "      <td>734</td>\n",
       "      <td>496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2088</th>\n",
       "      <td>2088</td>\n",
       "      <td>501</td>\n",
       "      <td>1931</td>\n",
       "      <td>281425</td>\n",
       "      <td>70311</td>\n",
       "      <td>496</td>\n",
       "      <td>734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2089</th>\n",
       "      <td>2089</td>\n",
       "      <td>501</td>\n",
       "      <td>1931</td>\n",
       "      <td>219</td>\n",
       "      <td>70311</td>\n",
       "      <td>734</td>\n",
       "      <td>496</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2090</th>\n",
       "      <td>2090</td>\n",
       "      <td>501</td>\n",
       "      <td>1931</td>\n",
       "      <td>281425</td>\n",
       "      <td>70317</td>\n",
       "      <td>496</td>\n",
       "      <td>734</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2091 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      index  league_id  season_id  venue_id  referee_id  localteam_id  \\\n",
       "0         0        501      18369      8914       14859            62   \n",
       "1         1        501      18369      8909       14853            53   \n",
       "2         2        501      18369      8914       18748            62   \n",
       "3         3        501      17141      8914       14468            62   \n",
       "4         4        501      17141      8909       14859            53   \n",
       "...     ...        ...        ...       ...         ...           ...   \n",
       "2086   2086        501       1932       219       17252           734   \n",
       "2087   2087        501       1931       219       70310           734   \n",
       "2088   2088        501       1931    281425       70311           496   \n",
       "2089   2089        501       1931       219       70311           734   \n",
       "2090   2090        501       1931    281425       70317           496   \n",
       "\n",
       "      visitorteam_id  localteam_position  visitorteam_position  \n",
       "0                 53                 2.0                   1.0  \n",
       "1                 62                 2.0                   1.0  \n",
       "2                 53                 6.0                   5.0  \n",
       "3                 53                 1.0                   2.0  \n",
       "4                 62                 2.0                   1.0  \n",
       "...              ...                 ...                   ...  \n",
       "2086             496                 0.0                   0.0  \n",
       "2087             496                 0.0                   0.0  \n",
       "2088             734                 0.0                   0.0  \n",
       "2089             496                 0.0                   0.0  \n",
       "2090             734                 0.0                   0.0  \n",
       "\n",
       "[2091 rows x 9 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "unknown-inspiration",
   "metadata": {},
   "source": [
    "# Modeling Experiments\n",
    "\n",
    "## CV\n",
    "\n",
    "Since we have different Ys, we are going to split the data once it for all the models, this would make the comparisson between models more fair.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "alternate-costs",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test, y_local_train, y_local_test,y_visitor_train, y_visitor_test = train_test_split(X,y, y_goals_local,y_goals_visitor, test_size=0.4, random_state=10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-vietnamese",
   "metadata": {},
   "source": [
    "## Modelo 1: Lasso with binary Y\n",
    "\n",
    "This is the simplest model with a binary y.\n",
    "As you can see, the $R^2$ is pretty low however the amount of predicted outcomes is modest. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "substantial-egypt",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 6.27\n",
      "R squared test set 4.53\n",
      "% of succesfully predicted matches train 63.48\n",
      "% of succesfully predicted matches test  61.29\n"
     ]
    }
   ],
   "source": [
    "# MODELO !\n",
    "\n",
    "# Lasso BINARY MODEL\n",
    "\n",
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "reg = Lasso(alpha=1)\n",
    "reg.fit(X_train, y_train)\n",
    "print('R squared training set', round(reg.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(reg.score(X_test, y_test)*100, 2))\n",
    "\n",
    "xtrain=reg.predict(X_train)\n",
    "xtest=reg.predict(X_test)\n",
    "partidos_train=sum(np.rint(np.nextafter(xtrain, xtrain+1))==y_train)/len(y_train)\n",
    "partidos_test=sum(np.rint(np.nextafter(xtest, xtest+1))==y_test)/len(y_test)\n",
    "print('% of succesfully predicted matches train', round(partidos_train*100,2))\n",
    "print('% of succesfully predicted matches test ', round(partidos_test*100,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "private-retro",
   "metadata": {},
   "source": [
    "## Modelo 2:  Lasso with numeric Y\n",
    "\n",
    "This is a pair of models that instead of using the binary Y they use as Y the number of goals scored by the local and the visitor, respectively. The design consists of estimating a linear model to estimate the goals of each of the two teams and later, we compare the goals of team 1 against those of team 2. This allows us to estimate the result and not only determine the winner. This is important because we could rescue the \"Draw\" category.\n",
    "\n",
    "We know that there are probably correlation problems between the home Y and the away Y, so it doesn't make much mathematical sense that we estimated two models independently, but we did it as an experiment. Surprisingly good results.\n",
    "\n",
    "We can explore how to make these types of models correctly in the future.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "published-power",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 6.78\n",
      "R squared test set 7.44\n",
      "R squared training set 4.92\n",
      "R squared test set 5.13\n",
      "% of succesfully predicted matches train 60.85\n",
      "% of succesfully predicted matches test 58.18\n"
     ]
    }
   ],
   "source": [
    "# Model 2\n",
    "\n",
    "reg2 = Lasso(alpha=1)\n",
    "model_local=reg2.fit(X_train, y_local_train)\n",
    "\n",
    "print('R squared training set', round(reg2.score(X_train, y_local_train)*100, 2))\n",
    "print('R squared test set', round(reg2.score(X_test, y_local_test)*100, 2))\n",
    "\n",
    "reg3 = Lasso(alpha=1)\n",
    "model_visitor=reg3.fit(X_train, y_visitor_train)\n",
    "print('R squared training set', round(reg3.score(X_train, y_visitor_train)*100, 2))\n",
    "print('R squared test set', round(reg3.score(X_test, y_visitor_test)*100, 2))\n",
    "\n",
    "\n",
    "partidos_test=sum((np.round(model_local.predict(X_test)) > np.round(model_visitor.predict(X_test)))==y_test)/len(y_test)\n",
    "partidos_train=sum((np.round(model_local.predict(X_train)) > np.round(model_visitor.predict(X_train)))==y_train)/len(y_train)\n",
    "print('% of succesfully predicted matches train', round(partidos_train*100,2))\n",
    "print('% of succesfully predicted matches test', round(partidos_test*100,2))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-bulgarian",
   "metadata": {},
   "source": [
    "## Model 2.5:  Lasso Extension with ties\n",
    "\n",
    "As the previous model allows us to estimate the expected goals, we can propose an alpha of such a size that it will help us to declare a tie if the expected goals are similar between both teams.\n",
    "\n",
    "For example, if the alpha is .11 in size, and if the expected goals are 1.95 and 2.05, for home and away, then we would be proposing a 2-2 tie.\n",
    "\n",
    "We notice that the number of correct matches decreases however, now we are talking about a problem of 3 categories, so the benchmark to beat would be a percentage of 1/3 of the matches. From this approach, the model performs well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "informed-montreal",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of succesfully predicted matches train 47.05\n",
      "% of succesfully predicted matches test 47.19\n"
     ]
    }
   ],
   "source": [
    "# Evaluacion con empate!\n",
    "indices_train=y_train.index[0:len(y_train)]\n",
    "indices_test=y_test.index[0:len(y_test)]\n",
    "pd_y_multi=pd.DataFrame(y_multi)\n",
    "pd_y_multi.index = new_index\n",
    "y_multi_train = pd_y_multi.filter(items = indices_train, axis=0)\n",
    "y_multi_test = pd_y_multi.filter(items = indices_test, axis=0)\n",
    "\n",
    "alpha = .05\n",
    "\n",
    "predict_multi_train = np.where(model_local.predict(X_train) > alpha + (model_visitor.predict(X_train)), \"Local\", \n",
    "                  np.where(model_local.predict(X_train) + alpha < model_visitor.predict(X_train), \"Visitante\", \"Empate\"))\n",
    "\n",
    "predict_multi_test = np.where(model_local.predict(X_test) > alpha + (model_visitor.predict(X_test)), \"Local\", \n",
    "                  np.where(model_local.predict(X_test) + alpha < model_visitor.predict(X_test), \"Visitante\", \"Empate\"))\n",
    "\n",
    "partidos_train=sum(y_multi_train[0]==predict_multi_train)/len(predict_multi_train)\n",
    "partidos_test=sum(y_multi_test[0]==predict_multi_test)/len(predict_multi_test)\n",
    "\n",
    "print('% of succesfully predicted matches train', round(partidos_train*100,2))\n",
    "print('% of succesfully predicted matches test', round(partidos_test*100,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "every-freedom",
   "metadata": {},
   "source": [
    "## Model 4:  Lasso CV\n",
    "\n",
    "This is an extension of model1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fallen-parcel",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R squared training set 5.74\n",
      "R squared test set 4.17\n",
      "% of succesfully predicted matches train 63.96\n",
      "% of succesfully predicted matches test 60.22\n"
     ]
    }
   ],
   "source": [
    "# Modelo 3 LASSO CV\n",
    "\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "# Lasso with 5 fold cross-validation\n",
    "model = LassoCV(cv=5, random_state=0, max_iter=10000)\n",
    "\n",
    "# Fit model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Set best alpha\n",
    "lasso_best = Lasso(alpha=model.alpha_)\n",
    "lasso_best.fit(X_train, y_train)\n",
    "print('R squared training set', round(lasso_best.score(X_train, y_train)*100, 2))\n",
    "print('R squared test set', round(lasso_best.score(X_test, y_test)*100, 2))\n",
    "\n",
    "xtrain=lasso_best.predict(X_train)\n",
    "xtest=lasso_best.predict(X_test)\n",
    "partidos_train=sum(np.rint(np.nextafter(xtrain, xtrain+1))==y_train)/len(y_train)\n",
    "partidos_test=sum(np.rint(np.nextafter(xtest, xtest+1))==y_test)/len(y_test)\n",
    "print('% of succesfully predicted matches train', round(partidos_train*100,2))\n",
    "print('% of succesfully predicted matches test', round(partidos_test*100,2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-association",
   "metadata": {},
   "source": [
    "## Modelo 4:  Logistic regression\n",
    "\n",
    "Es una version similar a las anteriores con Y binaria."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "chronic-selection",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of succesfully predicted matches train 56.46\n",
      "% of succesfully predicted matches test 56.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/marcoyel21/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_sag.py:352: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Modelo Logistic\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "model = LogisticRegression(\n",
    "    penalty='l1',\n",
    "    solver='saga',  # or 'liblinear'\n",
    "    C=.001)\n",
    "\n",
    "model=model.fit(X_train, y_train)\n",
    "partidos_train=model.score(X_train,y_train)\n",
    "partidos_test=model.score(X_test,y_test)\n",
    "\n",
    "print('% of succesfully predicted matches train', round(partidos_train*100,2))\n",
    "print('% of succesfully predicted matches test', round(partidos_test*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exotic-intro",
   "metadata": {},
   "source": [
    "## Modelo 4:  RF\n",
    "\n",
    "It is a version similar to the previous ones with binary Y. The advantage of this model is that it is very powerful and with so little data and preprocessing it achieves tremendous performance. This ir our champion model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "toxic-essay",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% of succesfully predicted matches train 67.46\n",
      "% of succesfully predicted matches test 64.01\n"
     ]
    }
   ],
   "source": [
    "### RF model\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.datasets import make_classification\n",
    "\n",
    "clf = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "partidos_train=clf.score(X_train,y_train)\n",
    "partidos_test=clf.score(X_test,y_test)\n",
    "\n",
    "print('% of succesfully predicted matches train', round(partidos_train*100,2))\n",
    "print('% of succesfully predicted matches test', round(partidos_test*100,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "funny-plaintiff",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "We will stick for now with the RF model (and later probably we will experiment with XBoosting) due to the flexibility of the inputs and predictive power. However, this exercise has served us to propose ad hoc metrics for our problem; extensions of the models that we could add to any version that we choose; to better select the data that we are going to use; and think about the way the models are going to be used in production, that is, what kind of data are they going to have before a match?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incredible-discount",
   "metadata": {},
   "source": [
    "After reading some blogs of other data scientits and by this experiments, we learned that:\n",
    "+ there is extreme noise in the data for this kind of models\n",
    "+ bad variables are very punishing, thats why simpler models were the most powerfull.\n",
    "+ Simple Random Forest can outperform regressions and even boosting methods and deep learning models.\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fossil-shower",
   "metadata": {},
   "source": [
    "# References\n",
    "\n",
    "[Lessons from experienced people in this kind of models](https://towardsdatascience.com/what-ive-learnt-predicting-soccer-matches-with-machine-learning-b3f8b445149d)\n",
    "\n",
    "[Different approaches to Y in this kind of models](https://medium.com/geekculture/building-a-simple-football-prediction-model-using-machine-learning-f061e607bec5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-breath",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
